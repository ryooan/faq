	/* NEED TO FIX MATHJAX
    <p>There are an infinite number of proper score functions, so the task of picking one at first seems a little daunting, but there are a few popular ones from which we can start. \[ S_{\rm log}(p) = \begin{cases} \log(p) & \text{if the outcome is $yes$} \\ \log(1-p) & \text{if the outcome is $no$} \end{cases} \\ S_{\rm quadratic/Brier}(p) = \begin{cases} -(1-p)^2 & \text{if the outcome is $yes$} \\ -p^2 & \text{if the outcome is $no$} \end{cases} \\ S_{\rm spherical}(p) = \begin{cases} \frac{p}{\sqrt{p^2 + (1-p)^2}} & \text{if the outcome is $yes$} \\ \frac{1-p}{\sqrt{p^2 + (1-p)^2}} & \text{if the outcome is $no$} \end{cases} \\ \] It's easy to account for the average community prediction \(p_c\) by adding a constant to each of these. For example, \(S_{\rm log}(p, p_c) = S_{\rm log}(p) - S_{\rm log}(p_c)\). This way a player would get precisely zero points if they just go along with the community average.</p>
    <p>We also introduce a set of betting functions in which a player's score is calculated as if they made a bet with the community setting the odds. \[ S_{\rm bet}(p, p_c) = \begin{cases} +(1-p_c) & \text{if the outcome is $yes$ and $p > p_c$} \\ -p_c & \text{if the outcome is $no$ and $p > p_c$} \\ -(1-p_c) & \text{if the outcome is $yes$ and $p
      < p_c$} \\ +p_c & \text{if the outcome is $no$ and $p < p_c$} \\ 0 & \text{if $p=p _c$} \end{cases} \\ \] This is the <em>constant pool</em>betting function, because the total number of points risked plus the total number potentially gained is equal to a constant. Similar functions can be defined where instead the total amount risked is set to a constant, the total amount gained is set to a constant, or anywhere in between (e.g., the <em>sqrt gain</em> function has the player gaining \(\sqrt{1-p_c}\) if the outcome is yes). Even though these functions are largely flat and cannot exactly be maximized, they are still proper scoring functions in the sense that the player cannot get a better score by predicting something other than the real-world probability, no matter what the community prediction happens to be.</p>
    <p>Of course, the scoring functions can be scaled by any constant without changing their properties. We have chosen a normalization such that average scores tend to fall in the range of 10-100 points. More specifically, each scoring function will yield exactly 100 points for a positive outcome if the player predicts 99% and the rest of the community predicts 50%. The relative scoring functions are further scaled by \[ \log\left(1 + \frac{n}{20}\right), \] where \(n\) is the total number of predictions (only counting the most recent prediction for each player).</p>
    <p>One nice thing about proper scoring functions is that any linear combination of different proper scoring functions will result in another proper scoring function. So, for example, we can combine the score based on one value of \(p_c\) with the score for another value of \(p_c\). This lets us create a fully relative scoring function \(R(p),\) where each player's score depends on each other player's guess, \[ R(p) = \frac{\sum_i S(p, p_i)}{n}, \] where the sum is over all other players' predictions. This is what is used in the above graph, and, with a combination of <em>log</em> scoring and <em>sqrt gain</em> betting (with values given by the defaults when you load this page), it's what's used to power the scoring on the Metaculus site.</p>
	
	*/